{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression applied to Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading and partitioning the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris(); X = iris.data.astype(np.float16); y = iris.target.astype(np.uint)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression:** $\\;$ implementation of logistic regression in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression(random_state=23).fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "print(f\"Test error: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warnings:** $\\;$ sklearn is a bit \"picky\" with warnings; we will ignore the warnings about convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solvers:** $\\;$ the `solver` parameter of LogisticRegression allows you to choose between different solvers (optimization algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error after training with the solver lbfgs: 0.0%\n",
      "Test error after training with the solver liblinear: 3.3%\n",
      "Test error after training with the solver newton-cg: 0.0%\n",
      "Test error after training with the solver newton-cholesky: 3.3%\n",
      "Test error after training with the solver sag: 0.0%\n",
      "Test error after training with the solver saga: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for solver in ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']:\n",
    "    clf = LogisticRegression(random_state=23, solver=solver, max_iter=10000).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Test error after training with the solver {solver!s}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tolerance:** $\\;$ the `tol` parameter sets a tolerance threshold to end training (1e4 by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error with tolerance 0.0001: 0.0%\n",
      "Test error with tolerance 0.01: 0.0%\n",
      "Test error with tolerance 1: 0.0%\n",
      "Test error with tolerance 100.0: 60.0%\n",
      "Test error with tolerance 10000.0: 60.0%\n"
     ]
    }
   ],
   "source": [
    "for tol in (1e-4, 1e-2, 1, 1e2, 1e4):\n",
    "    clf = LogisticRegression(tol=tol, random_state=23, max_iter=10000).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Test error with tolerance {tol}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization:** $\\;$ parameter `C` (positive, $1.0$ by default) de-regularizes the training criterion\n",
    "* **Possibility of under-adjustment:** $\\;$ with a value close to zero (maximum regularization)\n",
    "* **Possibility of overfitting:** $\\;$ with a very high positive value (minimum regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error with C 0.01: 6.7%\n",
      "Test error with C 0.1: 3.3%\n",
      "Test error with C 1: 0.0%\n",
      "Test error with C 10: 3.3%\n",
      "Test error with C 100: 3.3%\n"
     ]
    }
   ],
   "source": [
    "for C in (1e-2, 1e-1, 1, 1e1, 1e2):\n",
    "    clf = LogisticRegression(C=C, random_state=23, max_iter=10000).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Test error with C {C:g}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Early stopping:** $\\;$ saving computation and avoiding over-training (\"regularize\") by finishing earlier (in a few iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error with max_iter 10: 0.0%\n",
      "Test error with max_iter 20: 3.3%\n",
      "Test error with max_iter 50: 0.0%\n",
      "Test error with max_iter 100: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for max_iter in (10, 20, 50, 100):\n",
    "    clf = LogisticRegression(random_state=23, max_iter=max_iter).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Test error with max_iter {max_iter}: {err_test:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
